/**
 * Generated by Clara Agent Studio
 * Flow: Personal AI
 * Description: AI workflow generated from Clara Agent Studio
 * Generated at: 2025-06-01T15:10:02.660Z
 */

import { ClaraFlowRunner } from 'clara-flow-sdk';

export class PersonalAIFlow {
  constructor(options = {}) {
    this.runner = new ClaraFlowRunner({
      enableLogging: true,
      logLevel: 'info',
      ...options
    });
    
    this.flowData = {
  "format": "clara-sdk",
  "version": "1.0.0",
  "flow": {
    "id": "1748778912210-gt5myfm2a",
    "name": "Personal AI",
    "nodes": [
      {
        "id": "1748778913858-yc1sdo01m",
        "type": "input",
        "name": "Input",
        "position": {
          "x": -431.25841526480247,
          "y": 367.0096917294432
        },
        "data": {
          "label": "Input",
          "inputs": [],
          "outputs": [
            {
              "id": "output",
              "name": "Value",
              "type": "output",
              "dataType": "any",
              "description": "Input value"
            }
          ],
          "value": "hi "
        },
        "inputs": [],
        "outputs": [
          {
            "id": "output",
            "name": "Value",
            "type": "output",
            "dataType": "any",
            "description": "Input value"
          }
        ],
        "metadata": {
          "tags": [
            "input",
            "basic",
            "source"
          ],
          "documentation": "Provides input values to start or feed the workflow. Supports text, numbers, and JSON objects."
        }
      },
      {
        "id": "1748778916835-87arlbn16",
        "type": "llm",
        "name": "LLM Chat",
        "position": {
          "x": 243.53816411703315,
          "y": -183.5023898412678
        },
        "data": {
          "label": "LLM Chat",
          "inputs": [
            {
              "id": "system",
              "name": "System Message",
              "type": "input",
              "dataType": "string",
              "required": false,
              "description": "System prompt for the LLM"
            },
            {
              "id": "user",
              "name": "User Message",
              "type": "input",
              "dataType": "string",
              "required": true,
              "description": "User message/prompt"
            },
            {
              "id": "context",
              "name": "Pre-context",
              "type": "input",
              "dataType": "string",
              "required": false,
              "description": "Additional context to prepend"
            },
            {
              "id": "memory",
              "name": "Memory",
              "type": "input",
              "dataType": "array",
              "required": false,
              "description": "Conversation history array (messages with role and content)"
            },
            {
              "id": "image",
              "name": "Image",
              "type": "input",
              "dataType": "string",
              "required": false,
              "description": "Base64 encoded image data"
            }
          ],
          "outputs": [
            {
              "id": "response",
              "name": "Response",
              "type": "output",
              "dataType": "string",
              "description": "LLM response text"
            },
            {
              "id": "usage",
              "name": "Usage Stats",
              "type": "output",
              "dataType": "object",
              "description": "Token usage and cost information"
            }
          ],
          "apiBaseUrl": "http://192.168.1.36/ollama/v1",
          "apiKey": "sdad",
          "model": "gemma3:27b",
          "temperature": 0.7,
          "maxTokens": 1000
        },
        "inputs": [
          {
            "id": "system",
            "name": "System Message",
            "type": "input",
            "dataType": "string",
            "required": false,
            "description": "System prompt for the LLM"
          },
          {
            "id": "user",
            "name": "User Message",
            "type": "input",
            "dataType": "string",
            "required": true,
            "description": "User message/prompt"
          },
          {
            "id": "context",
            "name": "Pre-context",
            "type": "input",
            "dataType": "string",
            "required": false,
            "description": "Additional context to prepend"
          },
          {
            "id": "memory",
            "name": "Memory",
            "type": "input",
            "dataType": "array",
            "required": false,
            "description": "Conversation history array (messages with role and content)"
          },
          {
            "id": "image",
            "name": "Image",
            "type": "input",
            "dataType": "string",
            "required": false,
            "description": "Base64 encoded image data"
          }
        ],
        "outputs": [
          {
            "id": "response",
            "name": "Response",
            "type": "output",
            "dataType": "string",
            "description": "LLM response text"
          },
          {
            "id": "usage",
            "name": "Usage Stats",
            "type": "output",
            "dataType": "object",
            "description": "Token usage and cost information"
          }
        ],
        "metadata": {
          "tags": [
            "ai",
            "llm",
            "chat",
            "openai"
          ],
          "documentation": "Interfaces with OpenAI-compatible APIs for text and vision tasks."
        }
      },
      {
        "id": "1748778928358-6ddp1i7z5",
        "type": "input",
        "name": "Input",
        "position": {
          "x": -432.15197129517037,
          "y": -564.4049767553313
        },
        "data": {
          "label": "Input",
          "inputs": [],
          "outputs": [
            {
              "id": "output",
              "name": "Value",
              "type": "output",
              "dataType": "any",
              "description": "Input value"
            }
          ],
          "value": "You are Clara"
        },
        "inputs": [],
        "outputs": [
          {
            "id": "output",
            "name": "Value",
            "type": "output",
            "dataType": "any",
            "description": "Input value"
          }
        ],
        "metadata": {
          "tags": [
            "input",
            "basic",
            "source"
          ],
          "documentation": "Provides input values to start or feed the workflow. Supports text, numbers, and JSON objects."
        }
      },
      {
        "id": "1748784063388-scm95onzi",
        "type": "output",
        "name": "Output",
        "position": {
          "x": 845.798299700271,
          "y": -137.19918483751317
        },
        "data": {},
        "inputs": [
          {
            "id": "input",
            "name": "Value",
            "type": "input",
            "dataType": "any",
            "required": true,
            "description": "Value to output"
          }
        ],
        "outputs": [],
        "metadata": {
          "tags": [
            "output",
            "basic",
            "sink"
          ],
          "documentation": "Displays the final result with various formatting options."
        }
      }
    ],
    "connections": [
      {
        "id": "1748778924982-nrdgsyvk6",
        "sourceNodeId": "1748778913858-yc1sdo01m",
        "sourcePortId": "output",
        "targetNodeId": "1748778916835-87arlbn16",
        "targetPortId": "user"
      },
      {
        "id": "1748778936366-ksfc0gt2p",
        "sourceNodeId": "1748778928358-6ddp1i7z5",
        "sourcePortId": "output",
        "targetNodeId": "1748778916835-87arlbn16",
        "targetPortId": "system"
      },
      {
        "id": "1748790157595-fuy9r5ffv",
        "sourceNodeId": "1748778916835-87arlbn16",
        "sourcePortId": "response",
        "targetNodeId": "1748784063388-scm95onzi",
        "targetPortId": "input"
      }
    ],
    "customNodes": []
  },
  "metadata": {
    "createdAt": "2025-06-01T15:10:02.660Z",
    "exportedAt": "2025-06-01T15:10:02.660Z",
    "exportedFrom": "Clara Agent Studio",
    "hasCustomNodes": false
  }
};
    
    this.registerCustomNodes();
  }

  registerCustomNodes() {
    // Register all custom nodes used in this flow
    if (this.flowData.flow.customNodes) {
      this.flowData.flow.customNodes.forEach(node => {
        this.runner.registerCustomNode(node);
      });
    }
  }

  async execute(inputs = {}) {
    return await this.runner.executeFlow(this.flowData, inputs);
  }

  async executeBatch(inputSets, options = {}) {
    const { concurrency = 3, onProgress } = options;
    const results = [];
    
    for (let i = 0; i < inputSets.length; i += concurrency) {
      const batch = inputSets.slice(i, i + concurrency);
      const batchPromises = batch.map(inputs => this.execute(inputs));
      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);
      
      if (onProgress) {
        onProgress({
          completed: Math.min(i + concurrency, inputSets.length),
          total: inputSets.length,
          results: results
        });
      }
    }
    
    return results;
  }

  async executeWithCallback(inputs = {}, onNodeComplete = null) {
    return await this.runner.executeFlow(this.flowData, inputs, {
      onNodeComplete: onNodeComplete
    });
  }

  getFlowInfo() {
    return {
      name: this.flowData.flow.name,
      description: this.flowData.flow.description,
      nodeCount: this.flowData.flow.nodes.length,
      connectionCount: this.flowData.flow.connections.length,
      customNodeCount: this.flowData.flow.customNodes?.length || 0,
      hasCustomNodes: this.flowData.metadata.hasCustomNodes
    };
  }

  validate() {
    return this.runner.validateFlow(this.flowData);
  }
}

// Export for direct use
export const personalaiFlow = new PersonalAIFlow();
export default PersonalAIFlow;
