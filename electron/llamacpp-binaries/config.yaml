# Auto-generated llama-swap configuration
# Models directory: C:\Users\prave\.clara\llama-models
healthCheckTimeout: 30
logLevel: info

models:
  "gemma3:12b":
    proxy: "http://127.0.0.1:9999"
    cmd: |
      "C:\Users\prave\ClaraVerse\electron\llamacpp-binaries\win32-x64\llama-server.exe"
      -m "C:\Users\prave\.clara\llama-models\gemma-3-12b-it-Q4_K_M.gguf"
      --port 9999 --jinja --n-gpu-layers 30
    ttl: 300

groups:
  "default_group":
    swap: true
    exclusive: true
    members:
      - "gemma3:12b"
