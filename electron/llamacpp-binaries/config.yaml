# Auto-generated llama-swap configuration
# Models directory: /Users/badfy17g/.clara/llama-models
healthCheckTimeout: 30
logLevel: info

models:
  "qwen3:0.6b":
    proxy: "http://127.0.0.1:9999"
    cmd: |
      "/Users/badfy17g/ClaraVerse/electron/llamacpp-binaries/darwin-arm64/llama-server"
      -m "/Users/badfy17g/Downloads/Qwen3 0.6B GGUF.gguf"
      --port 9999 --jinja --n-gpu-layers 60 --threads 4 --ctx-size 4096 --batch-size 512 --ubatch-size 256 --keep 2048 --defrag-thold 0.1 --mlock --parallel 2
    env:
      - "DYLD_LIBRARY_PATH=/Users/badfy17g/ClaraVerse/electron/llamacpp-binaries/darwin-arm64:"
    ttl: 300

  "qwen3:30b":
    proxy: "http://127.0.0.1:9999"
    cmd: |
      "/Users/badfy17g/ClaraVerse/electron/llamacpp-binaries/darwin-arm64/llama-server"
      -m "/Users/badfy17g/Downloads/Qwen3-30B-A3B-Q4_K_M.gguf"
      --port 9999 --jinja --n-gpu-layers 60 --threads 4 --ctx-size 4096 --batch-size 512 --ubatch-size 256 --keep 2048 --defrag-thold 0.1 --mlock --parallel 2
    env:
      - "DYLD_LIBRARY_PATH=/Users/badfy17g/ClaraVerse/electron/llamacpp-binaries/darwin-arm64:"
    ttl: 300

groups:
  "default_group":
    swap: true
    exclusive: true
    members:
      - "qwen3:0.6b"
      - "qwen3:30b"
